{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a472e1b0",
   "metadata": {},
   "source": [
    "### **Dask-Based Random Forest Classifier on US Accident Data**\n",
    "#### **Introduction:**\n",
    "This project demonstrates the use of a distributed Random Forest model to classify accident severity using Dask's distributed computing capabilities. We'll:\n",
    "1. Use a cleaned dataset of US accidents.\n",
    "2. Preprocess the data.\n",
    "3. Train multiple Random Forest configurations.\n",
    "4. Evaluate and visualize the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.dataframe as dd\n",
    "from dask_ml.model_selection import train_test_split\n",
    "from dask_ml.preprocessing import MinMaxScaler\n",
    "from dask_ml.wrappers import ParallelPostFit\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e628dd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "em1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 9000\n",
      "        inet 10.99.252.133  netmask 255.255.0.0  broadcast 10.99.255.255\n",
      "        inet6 fe80::425c:fdff:fe81:cbea  prefixlen 64  scopeid 0x20<link>\n",
      "        ether 40:5c:fd:81:cb:ea  txqueuelen 1000  (Ethernet)\n",
      "        RX packets 161152277554  bytes 759861724509543 (691.0 TiB)\n",
      "        RX errors 17891  dropped 0  overruns 0  frame 17891\n",
      "        TX packets 155857343214  bytes 672134134924612 (611.3 TiB)\n",
      "        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n",
      "        device interrupt 64  memory 0x93000000-937fffff  \n",
      "\n",
      "lo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536\n",
      "        inet 127.0.0.1  netmask 255.0.0.0\n",
      "        inet6 ::1  prefixlen 128  scopeid 0x10<host>\n",
      "        loop  txqueuelen 1000  (Local Loopback)\n",
      "        RX packets 1084864512  bytes 11338178448591 (10.3 TiB)\n",
      "        RX errors 0  dropped 0  overruns 0  frame 0\n",
      "        TX packets 1084864512  bytes 11338178448591 (10.3 TiB)\n",
      "        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! ifconfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018f7fe8",
   "metadata": {},
   "source": [
    "#### 1. Initialize Dask Cluster\n",
    "This function sets up a dynamic Dask LocalCluster with workers and provides a link to the Dask dashboard for monitoring.\n",
    "\n",
    "##### Args:\n",
    "1. n_workers (int): Number of worker processes to start.\n",
    "2. threads_per_worker (int): Number of threads per worker process.\n",
    "3. memory_limit (str): Memory limit for each worker process.\n",
    "\n",
    "##### Returns:\n",
    "tuple: A tuple containing the Dask client and cluster objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_cluster(n_workers, threads_per_worker, memory_limit):\n",
    "    cluster = LocalCluster(\n",
    "        n_workers=0,\n",
    "        threads_per_worker=threads_per_worker,\n",
    "        memory_limit=memory_limit,\n",
    "        processes=True,\n",
    "    )\n",
    "    client = Client(cluster)\n",
    "    cluster.scale(n_workers)  # Dynamically scale to the desired number of workers\n",
    "    return client, cluster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438d7882",
   "metadata": {},
   "source": [
    "#### 2. Data Loading and Preprocessing\n",
    "This function loads the dataset using Dask, normalizes the features, performs feature engineering, and splits the data into training and test sets.\n",
    "\n",
    "##### Args:\n",
    "1. dataset_path (str): Path to the CSV dataset.\n",
    "2. features (list): List of feature column names.\n",
    "3. target (str): Name of the target column.\n",
    "\n",
    "##### Returns:\n",
    "tuple: Tuple of (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34390f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading_and_preprocessing(client, dataset_path, features, target):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses the dataset using the Dask cluster.\n",
    "    \"\"\"\n",
    "    df = dd.read_csv(dataset_path)\n",
    "    X = df[features]\n",
    "    Y = df[target]\n",
    "    scaler = MinMaxScaler()\n",
    "    X_normalized = scaler.fit_transform(X)\n",
    "    X_normalized['Temp_Wind'] = X_normalized['Temperature(F)'] * X_normalized['Wind_Speed(mph)']\n",
    "    X_normalized['Visibility_Wind'] = X_normalized['Visibility(mi)'] * X_normalized['Wind_Speed(mph)']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_normalized, \n",
    "        Y, \n",
    "        test_size=0.2, \n",
    "        random_state=42, \n",
    "        shuffle=False\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a0782f",
   "metadata": {},
   "source": [
    "#### 3. Model Training and Evaluation\n",
    "This function trains multiple Random Forest models with different configurations and evaluates their performance in terms of accuracy and time.\n",
    "\n",
    "#### Args:\n",
    "1. X_train (array): Training features.\n",
    "2. X_test (array): Testing features.\n",
    "3. y_train (array): Training target labels.\n",
    "4. y_test (array): Testing target labels.\n",
    "5. configurations (dict): Dictionary of hyperparameter configurations.\n",
    "6. client (dask.distributed.Client): Dask client object for parallel execution.\n",
    "\n",
    "#### Returns:\n",
    "dict: Dictionary containing evaluation results for each configuration.\n",
    "\n",
    "- 1Key: Configuration name (string)\n",
    "- Value: Dictionary with performance metrics\n",
    "    - 'accuracy' (float): Accuracy score achieved on the testing data\n",
    "    - 'time' (float): Time taken for training and evaluation (seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79f906ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training_and_evaluation(client, X_train, X_test, y_train, y_test, configurations):\n",
    "    \"\"\"\n",
    "    Trains and evaluates multiple Random Forest models with different configurations using the Dask cluster.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for config_name, params in configurations.items():\n",
    "        start_time = time.time()\n",
    "        with joblib.parallel_backend('dask'):\n",
    "            model = ParallelPostFit(RandomForestClassifier(**params))\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "        end_time = time.time()\n",
    "        accuracy = accuracy_score(y_test.compute(), y_pred.compute())\n",
    "        results[config_name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'time': end_time - start_time,\n",
    "        }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a53fb7f",
   "metadata": {},
   "source": [
    "#### 4. Sequential_execution\n",
    "Performs sequential data loading, preprocessing, training, and evaluation for Random Forest models with different configurations.\n",
    "\n",
    "\n",
    "#### Args:\n",
    "1. dataset_path (str): Path to the CSV dataset.\n",
    "2. features (list): List of feature column names.\n",
    "3. target (str): Name of the target column.\n",
    "4. model_configs (dict): Dictionary containing hyperparameter configurations for the models.\n",
    "\n",
    "#### Returns:\n",
    "dict: Dictionary containing evaluation results for each configuration.\n",
    "- Key: Configuration name (string)\n",
    "- Value: Dictionary with performance metrics\n",
    "    - 'accuracy' (float): Accuracy score achieved on the testing data\n",
    "    - 'time' (float): Time taken for training and evaluation (seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c117740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_execution(dataset_path, features, target, model_configs):\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    X = df[features]\n",
    "    Y = df[target]\n",
    "    scaler = MinMaxScaler()\n",
    "    X_normalized = scaler.fit_transform(X)\n",
    "    X_normalized['Temp_Wind'] = X_normalized['Temperature(F)'] * X_normalized['Wind_Speed(mph)']\n",
    "    X_normalized['Visibility_Wind'] = X_normalized['Visibility(mi)'] * X_normalized['Wind_Speed(mph)']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_normalized, Y, test_size=0.2, random_state=42, shuffle=False\n",
    "    )\n",
    "    \n",
    "    results = {}\n",
    "    for config_name, params in model_configs.items():\n",
    "        start_time = time.time()\n",
    "        model = RandomForestClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        end_time = time.time()\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        results[config_name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'time': end_time - start_time,\n",
    "        }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d1887a",
   "metadata": {},
   "source": [
    "#### 5. Visualization\n",
    "Visualizes performance metrics for cluster and model configurations using subplots.\n",
    "\n",
    "#### Args:\n",
    "1. cluster_results (dict): Dictionary containing cluster performance data.\n",
    "    - Keys: Configuration names (strings)\n",
    "    - Values: Dictionaries with performance metrics\n",
    "        - 'time' (float): Time taken for execution (seconds)\n",
    "        - 'accuracy' (float): Accuracy score achieved\n",
    "2. model_results (dict): Dictionary containing model performance data.\n",
    "    Same structure as cluster_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_performance(cluster_results, model_results):\n",
    "    \"\"\"\n",
    "    Visualizes performance metrics for different cluster and model configurations using line graphs.\n",
    "    \"\"\"\n",
    "    # Cluster Performance\n",
    "    cluster_configs = list(cluster_results.keys())\n",
    "    cluster_times = [cluster_results[config]['time'] for config in cluster_configs]\n",
    "    cluster_speedups = [cluster_results[config]['speedup'] for config in cluster_configs]\n",
    "    cluster_efficiencies = [cluster_results[config]['efficiency'] for config in cluster_configs]\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 18))\n",
    "\n",
    "    # Execution Time Graph\n",
    "    ax1.plot(cluster_configs, cluster_times, marker='o', color='orange', linewidth=2)\n",
    "    ax1.set_ylabel('Time (seconds)', color='orange')\n",
    "    ax1.set_title('Cluster Configuration Execution Time')\n",
    "    ax1.grid(True)\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Speedup Graph\n",
    "    ax2.plot(cluster_configs, cluster_speedups, marker='s', color='blue', linewidth=2)\n",
    "    ax2.set_ylabel('Speedup', color='blue')\n",
    "    ax2.set_title('Cluster Configuration Speedup')\n",
    "    ax2.grid(True)\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Efficiency Graph\n",
    "    ax3.plot(cluster_configs, cluster_efficiencies, marker='^', color='green', linewidth=2)\n",
    "    ax3.set_ylabel('Efficiency', color='green')\n",
    "    ax3.set_title('Cluster Configuration Efficiency')\n",
    "    ax3.grid(True)\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Model Performance\n",
    "    model_configs = list(model_results.keys())\n",
    "    model_times = [model_results[config]['time'] for config in model_configs]\n",
    "    model_accuracies = [model_results[config]['accuracy'] for config in model_configs]\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "    # Speed (Time) Graph\n",
    "    ax1.plot(model_configs, model_times, marker='o', color='purple', linewidth=2)\n",
    "    ax1.set_ylabel('Time (seconds)', color='purple')\n",
    "    ax1.set_title('Model Configuration Speed')\n",
    "    ax1.grid(True)\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Accuracy Graph\n",
    "    ax2.plot(model_configs, model_accuracies, marker='s', color='red', linewidth=2)\n",
    "    ax2.set_ylabel('Accuracy', color='red')\n",
    "    ax2.set_title('Model Configuration Accuracy')\n",
    "    ax2.grid(True)\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50148790",
   "metadata": {},
   "source": [
    "#### 6. Main Function\n",
    "The main() function orchestrates the entire process by calling the individual functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to test different cluster configurations and evaluate performance.\n",
    "    \"\"\"\n",
    "    dataset_path = \"../final_project/Cleaned_US_Accidents_March23.csv\"\n",
    "    features = ['Temperature(F)', 'Visibility(mi)', 'Wind_Speed(mph)']\n",
    "    target = 'Severity'\n",
    "\n",
    "    # Cluster configurations\n",
    "    cluster_configs = {\n",
    "        \"config_1\": {\"n_workers\": 4, \"threads_per_worker\": 2, \"memory_limit\": \"8GB\"},\n",
    "        \"config_2\": {\"n_workers\": 6, \"threads_per_worker\": 2, \"memory_limit\": \"12GB\"},\n",
    "        \"config_3\": {\"n_workers\": 8, \"threads_per_worker\": 4, \"memory_limit\": \"16GB\"},\n",
    "    }\n",
    "\n",
    "    # Model configurations\n",
    "    model_configs = {\n",
    "        'config_1': {'n_estimators': 50, 'max_depth': 3, 'random_state': 42},\n",
    "        'config_2': {'n_estimators': 100, 'max_depth': 3, 'random_state': 42},\n",
    "        'config_3': {'n_estimators': 150, 'max_depth': 5, 'random_state': 42},\n",
    "\n",
    "    }\n",
    "\n",
    "    print(\"Running sequential execution...\")\n",
    "    sequential_results = sequential_execution(dataset_path, features, target, model_configs)\n",
    "    sequential_time = sum([res['time'] for res in sequential_results.values()])\n",
    "\n",
    "    cluster_results = {}\n",
    "    model_results = {}\n",
    "\n",
    "    for config_name, config_params in cluster_configs.items():\n",
    "        print(f\"Testing {config_name}...\")\n",
    "        # Initialize cluster\n",
    "        client, cluster = initialize_cluster(**config_params)\n",
    "\n",
    "        try:\n",
    "            # Data loading and preprocessing\n",
    "            X_train, X_test, y_train, y_test = data_loading_and_preprocessing(\n",
    "                client, dataset_path, features, target\n",
    "            )\n",
    "\n",
    "            # Model training and evaluation\n",
    "            results = model_training_and_evaluation(client, X_train, X_test, y_train, y_test, model_configs)\n",
    "\n",
    "            # Collect performance metrics for the cluster\n",
    "            avg_accuracy = sum([res['accuracy'] for res in results.values()]) / len(results)\n",
    "            total_time = sum([res['time'] for res in results.values()])\n",
    "            speedup = sequential_time / total_time\n",
    "            efficiency = speedup / config_params['n_workers']\n",
    "            \n",
    "            cluster_results[config_name] = {\n",
    "                \"accuracy\": avg_accuracy,\n",
    "                \"time\": total_time,\n",
    "                \"speedup\": speedup,\n",
    "                \"efficiency\": efficiency\n",
    "            }\n",
    "\n",
    "            # Collect performance metrics for the models\n",
    "            model_results.update(results)\n",
    "\n",
    "        finally:\n",
    "            client.close()\n",
    "            cluster.close()\n",
    "\n",
    "    # Visualize the performance of different cluster and model configurations\n",
    "    visualize_performance(cluster_results, model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f492a643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sequential execution...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
