{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.dataframe as dd\n",
    "from dask_ml.model_selection import train_test_split, RandomizedSearchCV\n",
    "from dask_ml.preprocessing import MinMaxScaler\n",
    "from dask_ml.wrappers import ParallelPostFit\n",
    "import joblib\n",
    "from scipy.stats import uniform, loguniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "em1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 9000\n",
      "        inet 10.99.252.209  netmask 255.255.0.0  broadcast 10.99.255.255\n",
      "        inet6 fe80::425c:fdff:fe78:76f6  prefixlen 64  scopeid 0x20<link>\n",
      "        ether 40:5c:fd:78:76:f6  txqueuelen 1000  (Ethernet)\n",
      "        RX packets 10304440050  bytes 72694729140074 (66.1 TiB)\n",
      "        RX errors 0  dropped 0  overruns 0  frame 0\n",
      "        TX packets 12991805886  bytes 90338772785068 (82.1 TiB)\n",
      "        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n",
      "        device interrupt 65  memory 0x93000000-937fffff  \n",
      "\n",
      "lo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536\n",
      "        inet 127.0.0.1  netmask 255.0.0.0\n",
      "        inet6 ::1  prefixlen 128  scopeid 0x10<host>\n",
      "        loop  txqueuelen 1000  (Local Loopback)\n",
      "        RX packets 132858251  bytes 5134217238253 (4.6 TiB)\n",
      "        RX errors 0  dropped 0  overruns 0  frame 0\n",
      "        TX packets 132858251  bytes 5134217238253 (4.6 TiB)\n",
      "        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!ifconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_cluster(n_workers, threads_per_worker, memory_limit, processes):\n",
    "    \"\"\"Initialize Dask LocalCluster with specified configurations.\"\"\"\n",
    "    cluster = LocalCluster(\n",
    "        n_workers=n_workers,\n",
    "        threads_per_worker=threads_per_worker,\n",
    "        memory_limit=memory_limit,\n",
    "        processes=processes,\n",
    "        host='10.99.252.209',\n",
    "    )\n",
    "    client = Client(cluster)\n",
    "    print(f\"Dask Dashboard Link: {client.dashboard_link}\")\n",
    "    cluster.scale(n_workers)\n",
    "    return client, cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading_and_preprocessing(client, dataset_path, features, target):\n",
    "    \"\"\"Load and preprocess data using Dask.\"\"\"\n",
    "    df = dd.read_csv(dataset_path)\n",
    "    X = df[features]\n",
    "    Y = df[target]\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    X_normalized = scaler.fit_transform(X)\n",
    "    \n",
    "    # Feature engineering\n",
    "    X_normalized['Temp_Wind'] = X_normalized['Temperature(F)'] * X_normalized['Wind_Speed(mph)']\n",
    "    X_normalized['Visibility_Wind'] = X_normalized['Visibility(mi)'] * X_normalized['Wind_Speed(mph)']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_normalized, Y, test_size=0.2, random_state=42, shuffle=False\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training_and_evaluation(client, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Train and evaluate an SVM model using Dask with RandomizedSearchCV.\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Define the parameter space\n",
    "    param_space = {\n",
    "        'C': loguniform(1e-3, 1e3),\n",
    "        'kernel': ['rbf', 'linear', 'poly', 'sigmoid'],\n",
    "        'gamma': loguniform(1e-4, 1e0),\n",
    "    }\n",
    "    \n",
    "    with joblib.parallel_backend('dask'):\n",
    "        base_model = SVC(random_state=42)\n",
    "        search = RandomizedSearchCV(\n",
    "            estimator=base_model,\n",
    "            param_distributions=param_space,\n",
    "            n_iter=10,  # Number of parameter settings sampled\n",
    "            cv=3,\n",
    "            random_state=42\n",
    "        )\n",
    "        search.fit(X_train, y_train)\n",
    "        \n",
    "        best_model = ParallelPostFit(search.best_estimator_)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    \n",
    "    accuracy = accuracy_score(y_test.compute(), y_pred.compute())\n",
    "    \n",
    "    return {\"accuracy\": accuracy, \"time\": end_time - start_time, \"best_params\": search.best_params_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_performance(cluster_results):\n",
    "    \"\"\"Visualize execution time, speedup, and efficiency.\"\"\"\n",
    "    configs = list(cluster_results.keys())\n",
    "    times = [cluster_results[config]['time'] for config in configs]\n",
    "    speedups = [cluster_results[config]['speedup'] for config in configs]\n",
    "    efficiencies = [cluster_results[config]['efficiency'] for config in configs]\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 18))\n",
    "\n",
    "    # Execution Time Graph\n",
    "    ax1.plot(configs, times, marker='o', color='orange', linewidth=2)\n",
    "    ax1.set_ylabel('Time (seconds)', color='orange')\n",
    "    ax1.set_title('Execution Time')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Speedup Graph\n",
    "    ax2.plot(configs, speedups, marker='s', color='blue', linewidth=2)\n",
    "    ax2.set_ylabel('Speedup', color='blue')\n",
    "    ax2.set_title('Speedup')\n",
    "    ax2.grid(True)\n",
    "\n",
    "    # Efficiency Graph\n",
    "    ax3.plot(configs, efficiencies, marker='^', color='green', linewidth=2)\n",
    "    ax3.set_ylabel('Efficiency', color='green')\n",
    "    ax3.set_title('Efficiency')\n",
    "    ax3.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    dataset_path = \"Cleaned_US_Accidents_March23.csv\"\n",
    "    features = ['Temperature(F)', 'Visibility(mi)', 'Wind_Speed(mph)']\n",
    "    target = 'Severity'\n",
    "\n",
    "    # Cluster configurations: baseline uses processes=False; others use processes=True\n",
    "    cluster_configs = {\n",
    "        \"baseline_1_worker_1_thread\": {\"n_workers\": 20, \"threads_per_worker\": 2, \"memory_limit\": \"8GB\", \"processes\": True},\n",
    "        \"2\": {\"n_workers\": 10, \"threads_per_worker\": 1, \"memory_limit\": \"8GB\", \"processes\": True},\n",
    "        \"4\": {\"n_workers\": 12, \"threads_per_worker\": 1, \"memory_limit\": \"8GB\", \"processes\": True},\n",
    "        \"6\": {\"n_workers\": 14, \"threads_per_worker\": 1, \"memory_limit\": \"8GB\", \"processes\": True},\n",
    "        \"8\": {\"n_workers\": 16, \"threads_per_worker\": 1, \"memory_limit\": \"8GB\", \"processes\": True},\n",
    "        \"10\": {\"n_workers\": 18, \"threads_per_worker\": 1, \"memory_limit\": \"8GB\", \"processes\": True},\n",
    "    }\n",
    "\n",
    "    baseline_time = None\n",
    "    cluster_results = {}\n",
    "\n",
    "    for config_name, config_params in cluster_configs.items():\n",
    "        print(f\"Testing {config_name}...\")\n",
    "    \n",
    "        client, cluster = initialize_cluster(**config_params)\n",
    "\n",
    "        try:\n",
    "            X_train, X_test, y_train, y_test = data_loading_and_preprocessing(\n",
    "                client,\n",
    "                dataset_path,\n",
    "                features,\n",
    "                target\n",
    "            )\n",
    "            result = model_training_and_evaluation(client, X_train, X_test, y_train, y_test)\n",
    "\n",
    "            # Handle baseline configuration\n",
    "            if config_name == \"baseline_1_worker_1_thread\":\n",
    "                baseline_time = result[\"time\"]\n",
    "                if baseline_time is None or baseline_time <= 0:\n",
    "                    raise ValueError(\"Baseline time is not set or invalid. Ensure the baseline configuration runs correctly.\")\n",
    "                speedup = 1\n",
    "                efficiency = 1\n",
    "            else:\n",
    "                # Ensure baseline time is initialized before calculating speedup and efficiency\n",
    "                if baseline_time is None:\n",
    "                    raise ValueError(\"Baseline time has not been initialized. Run the baseline configuration first.\")\n",
    "                speedup = baseline_time / result[\"time\"]\n",
    "                efficiency = speedup / config_params[\"n_workers\"]\n",
    "\n",
    "            cluster_results[config_name] = {\n",
    "                \"accuracy\": result[\"accuracy\"],\n",
    "                \"time\": result[\"time\"],\n",
    "                \"speedup\": speedup,\n",
    "                \"efficiency\": efficiency,\n",
    "                \"best_params\": result[\"best_params\"]\n",
    "            }\n",
    "            \n",
    "            print(f\"Best parameters for {config_name}: {result['best_params']}\")\n",
    "            \n",
    "        finally:\n",
    "            client.close()\n",
    "            cluster.close()      \n",
    "\n",
    "    visualize_performance(cluster_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
